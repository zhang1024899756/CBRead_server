worker_processes 4;

# Keep logs of events http://nginx.org/en/docs/ngx_core_module.html#error_log
# error_log /var/log/nginx-error.log info;

events {
  # 这是高性能的关键——有很多可用的连接
  # 检查您的服务器的限制，运行这2个命令["ulimit -Hn"， "ulimit -Sn"]
  # Max # of clients = worker_connections * worker_processes
  # 每秒钟可以服务的用户总数 = worker_processes * worker_connections / (keepalive_timeout * 2)
  worker_connections 2048;

  # 使用epoll，这是一种可以提高性能的I/O处理方法，在Linux中很常用
  # http://nginx.org/en/docs/events.html
  use epoll;

  # 如果禁用multi_accept，工作进程将一次接受一个新连接
  # 否则，工作进程将一次接受所有新连接
  # http://nginx.org/en/docs/ngx_core_module.html#multi_accept
  multi_accept on;
}

http {
  # 我们的服务器组将被NGINX负载平衡
  # 3相同节点应用程序的副本
  upstream node-basie {
    least_conn;
    # 每个访问者的请求被路由到相同的服务器，除非他们改变了他们的IP地址
    # ip_hash;

    server nodeapp1:8080 weight=10 max_fails=3 fail_timeout=30s;
    # server nodeapp2:8080 weight=10 max_fails=3 fail_timeout=30s;
    # server nodeapp3:8080 weight=10 max_fails=3 fail_timeout=30s;
  }

  # The processing rate of requests coming from a single IP address
  # Create a rule to be used on defined server locations defined below inside "server {...}"
  limit_req_zone $binary_remote_addr zone=one:10m rate=18000r/m;

  # Allow X Connections per an IP address at a time
  # It is individually defined below inside "server {...}" for each location
  limit_conn_zone $binary_remote_addr zone=addr:10m;

  # Timeout for HTTP keep-alive connections
  #
  # https://en.wikipedia.org/wiki/HTTP_persistent_connection
  keepalive_timeout 65;
  keepalive_requests 100000; # Amount of keep-alive connections to allow at a time

  # 允许使用sendfile()在内核空间中直接传输数据
  # http://nginx.org/en/docs/http/ngx_http_core_module.html#sendfile
  sendfile on;
  tcp_nopush on; # 允许在FreeBSD和Linux中发送一个完整的包文件
  tcp_nodelay on; # 强制套接字发送它们在缓冲区中的数据

  # 设置读取客户端请求正文的缓冲区大小.
  # 如果请求主体大于缓冲区，则将整个请求主体或仅其部分写入临时文件
  client_body_buffer_size 128k;

  # 允许客户端请求的最大正文大小(在“Content-Length”请求报头字段中指定)
  client_max_body_size 10m;

  # 允许读取客户端请求头的缓冲区大小。对于大多数请求，1K字节的缓冲区就足够了
  client_header_buffer_size 1k;

  # 请求行不能超过一个缓冲区的大小，否则会返回414 (request - uri Too Large)错误给客户端
  large_client_header_buffers 4 4k;

  server {
    listen 80;

    # 在错误页面和“Server”响应头字段中隐藏NGINX版本
    server_tokens off;

    # 启用gzip压缩静态文件
    gzip on;

    # Internet Explorer v1-6禁用gzip
    gzip_disable "MSIE [1-6]\.";

    # 设置响应的gzip压缩级别。可接受的值在1到9的范围内(更高的值意味着更多的压缩)
    # Level 5 is very common
    gzip_comp_level 5;

    # 根据客户端浏览器是否支持gzip，它们接收的是压缩版本的文件还是未压缩版本的文件
    # 现在，如果缓存的是压缩版本，而浏览器不支持，NGINX不知道如何查找源文件
    # 如果Vary头文件不在那里，可能会向客户端提供不支持的文件
    gzip_vary on;

    # 设置将被gzip的响应的最小长度，仅从“Content-Length”响应报头字段确定
    gzip_min_length 1000;

    # 根据请求和响应启用或禁用对代理请求的响应进行gzip
    gzip_proxied any;

    # 如果客户端浏览器接受编码，并且文件长度大于上面的gzip_min_length，那么将被gzip压缩的文件类型
    gzip_types application/x-javascript text/css application/javascript text/javascript text/plain text/xml application/json application/vnd.ms-fontobject application/x-font-opentype application/x-font-truetype application/x-font-ttf application/xml font/eot font/opentype font/otf image/svg+xml image/vnd.microsoft.icon;

    # 设置用于压缩响应的缓冲区的数量和大小。默认情况下，缓冲区大小等于一个内存页
    # 这是4K或8K，取决于平台.
    gzip_buffers 16 8k;

    # 对xxxxxxx.com/*的任何请求
    location / {
      # 应用“来自单个IP地址的请求的处理速率”规则(上面确定)
      limit_req zone=one;

      # 应用“来自单个IP地址的最大连接数”规则(上面确定的)
      limit_conn addr 10;

      # 将请求映射到这个URL (ping是上面定义的上游)
      proxy_pass http://node-basie/;
      proxy_http_version 1.1;

      # 将客户端IP地址传递给上游服务器(可用于负载均衡，根据IP地址分配负载)
      proxy_set_header Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

      # 告诉上游服务器请求是通过NGINX代理的，没有具体的用例，但可能有用
      proxy_set_header X-NginX-Proxy true;

      # 当复制的服务器之一宕机时(例如，容器正在更新最新版本，并将很快恢复)
      # NGINX将只等待2秒连接到它，如果不成功，将转移到另一个
      proxy_connect_timeout 2;
      proxy_buffer_size 4k;
      proxy_buffers 4 32k;
      proxy_busy_buffers_size 64k;
      proxy_temp_file_write_size 64k;
      proxy_temp_path /etc/nginx/proxy_temp;

      # 设置将请求传输到代理服务器的超时时间
      # 超时设置仅在两个连续的写/读操作之间，而不是整个请求的传输
      proxy_send_timeout 600;
      proxy_read_timeout 600;
    }
  }
}